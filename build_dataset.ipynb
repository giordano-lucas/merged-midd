{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read all MIDD data files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "\n",
    "def midd_files(DIRECTORY = 'midd', n_layouts=4):\n",
    "   \"\"\"\n",
    "   Generator on all files in the MIDD datasets (all layouts)\n",
    "   \n",
    "   return a generator of tuples [(str,str,int)] : (\n",
    "      name of the file,\n",
    "      relative path to the file,\n",
    "      id of the layout of the file\n",
    "      )\n",
    "   \"\"\"\n",
    "   def all_files_in_dir(directory):\n",
    "      \"\"\"return all file names stored in the specified directory\"\"\"\n",
    "      filenames = next(walk(directory), (None, None, []))[2]  # [] if no file\n",
    "      return filenames\n",
    "   # iterate over layouts\n",
    "   for layout_id in range(n_layouts):\n",
    "      layout_dir = f'{DIRECTORY}/layout{layout_id}'\n",
    "      for file_name in all_files_in_dir(layout_dir):\n",
    "         file_path = f\"{layout_dir}/{file_name}\"\n",
    "         yield file_name.split(\".\")[0], file_path, layout_id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conversion of string fields to interger"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class IdMapper():\n",
    "   def __init__(self):\n",
    "      def gen_id(): # simple integer generator\n",
    "         id = -1\n",
    "         while True:\n",
    "            id = id + 1\n",
    "            yield id\n",
    "      self.gen_id = gen_id()\n",
    "      self.map = {}\n",
    "      self.is_built = False\n",
    "\n",
    "   def add_item(self,item:str):\n",
    "      if self.is_built:\n",
    "         raise ValueError('Cannot call add_item on a built IdMapper')\n",
    "      if item not in self.map.keys():\n",
    "         id = next(self.gen_id)\n",
    "         self.map[item]=id\n",
    "      return self.map[item]\n",
    "\n",
    "   def build(self):\n",
    "      if self.is_built:\n",
    "         raise ValueError('IdMapper is already built')\n",
    "      self.is_built = True\n",
    "      return self.map\n",
    "\n",
    "class Metadata():\n",
    "   def __init__(self,convert=False):\n",
    "      self.ner_tags = IdMapper()\n",
    "      self.convert  = convert\n",
    "\n",
    "   def add(self, record):\n",
    "      if self.convert:\n",
    "         converted_ner_tag = []\n",
    "      for tag in record['ner_tag']:\n",
    "         tag_id = self.ner_tags.add_item(tag)\n",
    "         if self.convert:\n",
    "            converted_ner_tag.append(tag_id)\n",
    "\n",
    "      if self.convert:\n",
    "         record['ner_tag'] = converted_ner_tag\n",
    "      return record\n",
    "\n",
    "   def build(self):\n",
    "      return {\n",
    "         'ner_tag' : self.ner_tags.build()\n",
    "      }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final steps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "def build_dataset(convert = False):\n",
    "    \n",
    "    dataset = []\n",
    "    metadata = Metadata(convert=convert)\n",
    "    for file_name, file_path, layout_id in midd_files():\n",
    "        df = pd.read_csv(file_path)\n",
    "        record = {   \n",
    "            \"name\": file_name,\n",
    "            \"layout\":layout_id,\n",
    "            'ner_tag':df.Tag.tolist(),\n",
    "            'token':df.Text.tolist()\n",
    "        }\n",
    "        record = metadata.add(record)\n",
    "        dataset.append(record)\n",
    "\n",
    "    return metadata.build(),dataset\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "def write_json(meta, dataset, DIRECTORY='data'):\n",
    "    \"\"\"Write the files to disk in JSON format\"\"\"\n",
    "    with open(f'{DIRECTORY}/meta.json', 'w') as meta_file:  #open the file in write mode\n",
    "        meta_file.write(json.dumps(meta))\n",
    "    with open(f'{DIRECTORY}/midd.json', 'w') as data_file:  #open the file in write mode\n",
    "        data_file.write(json.dumps(dataset))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# write both converted and non-converted version\n",
    "for convert in [True,False]:\n",
    "    meta,dataset = build_dataset(convert=convert)\n",
    "    write_json(\n",
    "        meta,\n",
    "        dataset,\n",
    "        DIRECTORY=f\"data/{'converted' if convert else 'simple'}\"\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('wagdoc': conda)"
  },
  "interpreter": {
   "hash": "c0666b40b71ffc40fa50e6bd15b670ad079419ced208c978bf6e613dabd8ca0a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}